---
title: "Benchmark Evaluation"
author: "Ben Weinstein"
date: "`r Sys.Date()`"
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
```

# Submission Format

The format of the submission is as follows

* A csv file
* 5 columns: Plot Name, xmin, ymin, xmax, ymax

Each row contains information for one predicted bounding box.

The plot column should be named the same as the files in the dataset (e.g. SJER_021)

```{r}
library(dplyr)
library(NeonTreeEvaluation)
library(reshape2)
library(ggplot2)
library(stringr)

#read and label each submission
f<-list.files("Submissions/",full.names = T)
df<-lapply(f,function(x){
  df<-read.csv(x)
  #Method name
  method<-str_match(x,"\\/(\\w+).csv")[,2]
  df<-df %>% mutate(Method=method)
  return(df)
})

#name list
names(df)<-sapply(f,function(x) {str_match(x,"\\/(\\w+).csv")[,2]})
```

# Evaluation

For each plot compute the precision and recall based on intersection-over-union of 0.5 between the ground truth bounding boxes and the predicted boxes. 

```{r, message=FALSE,warning=FALSE,include=FALSE}
#Run for each method.

Silva2016_results<-evaluate_benchmark(df[["Silva2016"]], project_boxes=FALSE,show=FALSE) %>%  mutate(Method="Silva2016")

Dalponte2016_results<-evaluate_benchmark(df[["Dalponte2016"]], project_boxes=FALSE,show=FALSE) %>%  mutate(Method="Dalponte2016")

Li2012_results<-evaluate_benchmark(df[["Li2012"]], project_boxes=FALSE,show=FALSE) %>%  mutate(Method="Li2012")

Weinstein2019_results<-evaluate_benchmark(df[["Weinstein2019"]], project_boxes=TRUE,show=F) %>%  mutate(Method="Weinstein2019")
```

```{r}
Weinstein_unpublished_results<-evaluate_benchmark(df[["Weinstein_unpublished"]], project_boxes=TRUE,show=T) %>% mutate(Method="Weinstein_unpublished")

results<-bind_rows(list(Weinstein2019_results,Silva2016_results,Weinstein_unpublished_results,Dalponte2016_results,Li2012_results))
```

## Summary Statistics

```{r}
sum_result<-results %>% group_by(Method) %>% do(summary_statistics(.,method="all"))
sum_result
ggplot(sum_result) + geom_point(aes(x=recall,y=precision,col=Method),size=4)
```

```{r,include=FALSE}
site_result<-results %>% group_by(Method) %>% do(summary_statistics(.,method="site"))
```

```{r}
#order by best
best_method<-sum_result %>% ungroup() %>% top_n(1)
site_order<-site_result %>% filter(Method==best_method$Method) %>% arrange(recall) %>% .$Site

site_result<-melt(site_result,id.vars = c("Site","Method"))
site_result$Site<-factor(site_result$Site,levels=site_order)
ggplot(site_result,aes(x=Site,y=value,col=Method)) + geom_point(size=2) + facet_wrap(~variable) + coord_flip()
```

# Stem recall

Using the NEON woody vegetation data, what proportion of field collected stems are within a predicted tree crown. Predictions can only match one stem, if multiple stems are within the bounding box.

```{r}
stem_recall1<-stem_detection(submission=df[["Silva2016"]],project_boxes = F,show=T) %>% mutate(Method="Silva2016")

stem_recall2<-stem_detection(submission=df[["Dalponte2016"]],project_boxes = F,show=F) %>% mutate(Method="Dalponte2016")

stem_recall3<-stem_detection(submission=df[["Weinstein_unpublished"]],project_boxes = T,show=F) %>% mutate(Method="Weinstein_unpublished")

stem_recall4<-stem_detection(submission=df[["Li2012"]],project_boxes = F,show=F) %>% mutate(Method="Li2012")

stem_recall5<-stem_detection(submission=df[["Weinstein2019"]],project_boxes = T,show=F) %>% mutate(Method="Weinstein2019")

stem_recalls<-bind_rows(stem_recall1,stem_recall2,stem_recall3,stem_recall4,stem_recall5)

stem_recalls %>% group_by(Method) %>% summarize(mean=mean(stem_recall,na.rm=T))
```


